# 20項目評価精度計算スクリプト

このスクリプトは、会話の印象に対する20個の評価項目について、モデルの予測精度を計算します。

## 機能

### 計算される精度指標

各評価項目について以下の指標を計算します：

1. ** (Mean Absolute Error)** - 平均絶対誤差
   - 予測値と正解値の絶対誤差の平均
   - 値が小さいほど精度が高い

2. **RMSE (Root Mean Square Error)** - 二乗平均平方根誤差
   - 予測値と正解値の二乗誤差の平均の平方根
   - 大きな誤差により重いペナルティを与える

3. **誤差1での正解率** - Accuracy within 1
   - 予測値と正解値の誤差が1以下の割合（パーセンテージ）
   - 実用的な精度の指標

### 評価項目（20項目）

1. 聴いてもらえた、わかってもらえたと感じた
2. 尊重されたと感じた
3. 新しい気づきや体験があった
4. 希望や期待を感じられた
5. 取り組みたかったことを扱えた
6. 一緒に考えながら取り組めた
7. やりとりのリズムがあっていた
8. 居心地のよいやりとりだった
9. 全体として適切でよかった
10. 今回の相談は価値があった
11. 相談開始の円滑さ
12. 相談終了のタイミング（不必要に聴きすぎていないか）、円滑さ
13. 受容・共感
14. 肯定・承認
15. 的確な質問による会話の促進
16. 要約
17. 問題の明確化
18. この相談での目標の明確化
19. 次の行動につながる提案
20. 勇気づけ・希望の喚起

## 使用方法

### 基本的な使用方法

```bash
# 仮想環境をアクティベート（メモリに基づく）
source venv/bin/activate  # または適切な仮想環境のアクティベートコマンド

# 20項目評価を実行
python src/core/feedback/evaluate_multi_item_accuracy.py
```

### オプション

```bash
# 評価サンプル数を制限（テスト用）
python src/core/feedback/evaluate_multi_item_accuracy.py --max-samples 5

# デバッグモードで実行
python src/core/feedback/evaluate_multi_item_accuracy.py --debug

# ヘルプを表示
python src/core/feedback/evaluate_multi_item_accuracy.py --help
```

## 前提条件

### 必要なファイル

1. **バッチ結果ファイル**: `openai_sft_outputs/batch_fine_tuning_results_*.json`
   - ファインチューニング済みモデルのIDが含まれている

2. **テストデータファイル**: `openai_sft_outputs/test_data_*.jsonl`
   - 評価用のテストデータ（会話テキストと正解スコア）

### 環境設定

1. **OpenAI APIキー**: `.env`ファイルに`OPENAI_API_KEY`を設定

2. **必要なPythonパッケージ**:
   ```bash
   pip install openai pandas numpy scikit-learn python-dotenv
   ```

## 出力ファイル

### 1. 詳細結果 (JSON)
ファイル名: `multi_item_detailed_results_YYYYMMDD_HHMMSS.json`

各サンプルの予測結果と正解データを含む詳細な結果

### 2. 精度指標 (CSV)
ファイル名: `multi_item_metrics_YYYYMMDD_HHMMSS.csv`

| 列名 | 説明 |
|------|------|
| model_id | モデルID |
| evaluation_item | 評価項目名 |
|  | 平均絶対誤差 |
| rmse | 二乗平均平方根誤差 |
| accuracy_within_1 | 誤差1での正解率（%） |
| sample_count | 有効サンプル数 |

## 出力例

```
📊 20項目評価結果サマリー 📊
================================================================================

🤖 モデル: ft:gpt-3.5-turbo-0125:example::12345678
------------------------------------------------------------

📈 全体平均:
    (平均絶対誤差): 0.845
   RMSE (二乗平均平方根誤差): 1.123
   誤差1での正解率: 78.5%
   有効項目数: 20/20

🏆 最良項目 TOP3:
   0.654 - 聴いてもらえた、わかってもらえたと感じた
   0.698 - 尊重されたと感じた
   0.723 - 居心地のよいやりとりだった

⚠️ 改善項目 TOP3:
   1.234 - 次の行動につながる提案
   1.156 - この相談での目標の明確化
   1.089 - 問題の明確化
```

## 注意事項

### データ構造の調整

現在のスクリプトでは、テストデータの正解スコアの抽出部分（`parse_correct_scores_from_sample`メソッド）が仮実装になっています。実際のデータ構造に合わせて以下を修正してください：

1. **JSON形式の場合**:
   ```python
   score_data = json.loads(assistant_message)
   ```

2. **テキスト形式の場合**:
   ```python
   # 正規表現パターンを実際の形式に合わせて調整
   score_match = re.search(r'(\d+(?:\.\d+)?)', line)
   ```

### API制限

- OpenAI APIの制限に注意してください
- 大量のサンプルを評価する場合は、`--max-samples`オプションでテストしてから実行することを推奨します
- API呼び出し間に1秒の待機時間を設けています

### メモリ使用量

20項目 × サンプル数 × モデル数のAPI呼び出しが発生するため、大規模な評価では時間とコストがかかります。

## トラブルシューティング

### よくあるエラー

1. **"バッチ結果ファイルが見つかりません"**
   - `openai_sft_outputs/`ディレクトリに結果ファイルがあることを確認

2. **"テストデータファイルが見つかりません"**
   - テストデータファイルの存在と形式を確認

3. **"正解データの解析に失敗"**
   - `parse_correct_scores_from_sample`メソッドを実際のデータ構造に合わせて修正

4. **API呼び出しエラー**
   - OpenAI APIキーが正しく設定されていることを確認
   - API制限に達していないか確認

### ログレベルの調整

デバッグ情報を詳しく見たい場合：
```bash
python src/core/feedback/evaluate_multi_item_accuracy.py --debug
```
