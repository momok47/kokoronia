#!/usr/bin/env python3
"""
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’è©³ã—ãèª¿æŸ»ã—ã€æ­£è§£ã‚¹ã‚³ã‚¢æŠ½å‡ºã®å•é¡Œã‚’ç‰¹å®šã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Any
import pandas as pd

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

class TestDataStructureAnalyzer:
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, output_dir: str = "openai_sft_outputs"):
        self.output_dir = Path(output_dir)
    
    def validate_data_structure(self):
        """ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼ï¼ˆkokorochatã®æ­£ã—ã„æ§‹é€ ã«å¯¾å¿œï¼‰"""
        logger.info("ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼ã—ã¾ã™")
        
        # å…ƒã®kokorochatãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        logger.info("\n=== å…ƒã®kokorochatãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª ===")
        original_data_files = list(self.output_dir.glob("*kokorochat*.jsonl"))
        if original_data_files:
            logger.info(f"å…ƒã®kokorochatãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {len(original_data_files)}å€‹")
            for file in original_data_files:
                logger.info(f"  {file.name}")
                # æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã®æ§‹é€ ã‚’ç¢ºèª
                try:
                    with open(file, 'r', encoding='utf-8') as f:
                        first_line = f.readline().strip()
                        if first_line:
                            sample = json.loads(first_line)
                            logger.info(f"    æ§‹é€ : {list(sample.keys())}")
                            if 'review_by_client_jp' in sample:
                                review_data = sample['review_by_client_jp']
                                if isinstance(review_data, dict):
                                    logger.info(f"    è©•ä¾¡é …ç›®æ•°: {len(review_data)}")
                                    # æœ€åˆã®æ•°é …ç›®ã®ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
                                    for i, (key, value) in enumerate(review_data.items()):
                                        if i < 3:  # æœ€åˆã®3é …ç›®ã®ã¿
                                            logger.info(f"      {key}: {value}")
                                        else:
                                            break
                except Exception as e:
                    logger.error(f"    ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            logger.warning("å…ƒã®kokorochatãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            logger.warning("ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®å‰å¾Œã§æ¯”è¼ƒã§ãã¾ã›ã‚“")
        
        # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        required_files = [
            "train_data_*.jsonl",
            "valid_data_*.jsonl", 
            "test_data_*.jsonl"
        ]
        
        missing_files = []
        for pattern in required_files:
            files = list(self.output_dir.glob(pattern))
            if not files:
                missing_files.append(pattern)
            else:
                logger.info(f"{pattern}: {len(files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        
        if missing_files:
            logger.warning(f"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_files}")
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’ç¢ºèª
        for pattern in required_files:
            files = list(self.output_dir.glob(pattern))
            if files:
                latest_file = max(files, key=lambda x: x.stat().st_mtime)
                self._analyze_file_structure(latest_file, pattern)
        
        # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®å•é¡Œã‚’ç‰¹å®š
        self._identify_data_conversion_issues()
    
    def _analyze_file_structure(self, file_path: Path, file_type: str):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’åˆ†æ"""
        logger.info(f"\n=== {file_type} ã®æ§‹é€ åˆ†æ ===")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                # æœ€åˆã®æ•°è¡Œã‚’èª­ã¿è¾¼ã‚“ã§æ§‹é€ ã‚’ç¢ºèª
                sample_count = 0
                structure_summary = {}
                
                for i, line in enumerate(f):
                    if i >= 10:  # æœ€åˆã®10ã‚µãƒ³ãƒ—ãƒ«ã®ã¿
                        break
                    
                    sample = json.loads(line.strip())
                    sample_count += 1
                    
                    # ã‚­ãƒ¼ã®æ§‹é€ ã‚’è¨˜éŒ²
                    keys = tuple(sorted(sample.keys()))
                    if keys not in structure_summary:
                        structure_summary[keys] = 0
                    structure_summary[keys] += 1
                    
                    # æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã®è©³ç´°è¡¨ç¤º
                    if i == 0:
                        logger.info(f"æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã®æ§‹é€ :")
                        for key, value in sample.items():
                            if isinstance(value, dict):
                                logger.info(f"  {key}: dict with keys {list(value.keys())}")
                            elif isinstance(value, list):
                                logger.info(f"  {key}: list with {len(value)} items")
                            else:
                                logger.info(f"  {key}: {type(value).__name__}")
                
                logger.info(f"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {sample_count}")
                logger.info(f"æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³:")
                for keys, count in structure_summary.items():
                    logger.info(f"  {keys}: {count}ã‚µãƒ³ãƒ—ãƒ«")
                
                # æ­£è§£ã‚¹ã‚³ã‚¢ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                self._check_ground_truth_availability(file_path, file_type)
                
        except Exception as e:
            logger.error(f"{file_path} ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _check_ground_truth_availability(self, file_path: Path, file_type: str):
        """æ­£è§£ã‚¹ã‚³ã‚¢ã®å¯ç”¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆkokorochatã®æ­£ã—ã„æ§‹é€ ã«å¯¾å¿œï¼‰"""
        logger.info(f"\n--- {file_type} ã®æ­£è§£ã‚¹ã‚³ã‚¢å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯ ---")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                # æœ€åˆã®100ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                ground_truth_found = 0
                score_keys = []
                structure_analysis = {
                    'has_dialogue': 0,
                    'has_topic': 0,
                    'has_review_by_client_jp': 0,
                    'has_review_by_client_en': 0,
                    'has_messages_only': 0,
                    'other_keys': set()
                }
                
                for i, line in enumerate(f):
                    if i >= 100:
                        break
                    
                    sample = json.loads(line.strip())
                    
                    # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’åˆ†æ
                    if 'dialogue' in sample:
                        structure_analysis['has_dialogue'] += 1
                    if 'topic' in sample:
                        structure_analysis['has_topic'] += 1
                    if 'review_by_client_jp' in sample:
                        structure_analysis['has_review_by_client_jp'] += 1
                    if 'review_by_client_en' in sample:
                        structure_analysis['has_review_by_client_en'] += 1
                    if 'messages' in sample and len(sample.keys()) == 1:
                        structure_analysis['has_messages_only'] += 1
                    
                    # ãã®ä»–ã®ã‚­ãƒ¼ã‚’è¨˜éŒ²
                    for key in sample.keys():
                        if key not in ['dialogue', 'topic', 'review_by_client_jp', 'review_by_client_en', 'messages']:
                            structure_analysis['other_keys'].add(key)
                    
                    # æ­£è§£ã‚¹ã‚³ã‚¢ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‚­ãƒ¼ã‚’æ¢ã™
                    for key, value in sample.items():
                        if isinstance(value, (int, float)) and 0 <= value <= 5:
                            if key not in score_keys:
                                score_keys.append(key)
                            ground_truth_found += 1
                            break
                        
                        elif isinstance(value, dict):
                            for sub_key, sub_value in value.items():
                                if isinstance(sub_value, (int, float)) and 0 <= sub_value <= 5:
                                    full_key = f"{key}.{sub_key}"
                                    if full_key not in score_keys:
                                        score_keys.append(full_key)
                                    ground_truth_found += 1
                                    break
                            if ground_truth_found > 0:
                                break
                
                # çµæœã‚’è¡¨ç¤º
                logger.info(f"æ­£è§£ã‚¹ã‚³ã‚¢ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«: {ground_truth_found}/100")
                if score_keys:
                    logger.info(f"ç™ºè¦‹ã•ã‚ŒãŸã‚¹ã‚³ã‚¢ã‚­ãƒ¼: {score_keys}")
                else:
                    logger.warning("æ­£è§£ã‚¹ã‚³ã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼")
                
                # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆ†æçµæœã‚’è¡¨ç¤º
                logger.info(f"\n--- ãƒ‡ãƒ¼ã‚¿æ§‹é€ åˆ†æ ---")
                logger.info(f"dialogueã‚’å«ã‚€: {structure_analysis['has_dialogue']}/100")
                logger.info(f"topicã‚’å«ã‚€: {structure_analysis['has_topic']}/100")
                logger.info(f"review_by_client_jpã‚’å«ã‚€: {structure_analysis['has_review_by_client_jp']}/100")
                logger.info(f"review_by_client_enã‚’å«ã‚€: {structure_analysis['has_review_by_client_en']}/100")
                logger.info(f"messagesã®ã¿ï¼ˆå˜ç´”åŒ–ï¼‰: {structure_analysis['has_messages_only']}/100")
                
                if structure_analysis['other_keys']:
                    logger.info(f"ãã®ä»–ã®ã‚­ãƒ¼: {structure_analysis['other_keys']}")
                
                # å•é¡Œã®ç‰¹å®š
                if structure_analysis['has_messages_only'] > 0:
                    logger.warning(f"âš ï¸  {structure_analysis['has_messages_only']}ã‚µãƒ³ãƒ—ãƒ«ãŒå˜ç´”åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼ˆmessagesã‚­ãƒ¼ã®ã¿ï¼‰")
                    logger.warning("  ã“ã‚ŒãŒæ­£è§£ã‚¹ã‚³ã‚¢ãŒæŠ½å‡ºã§ããªã„åŸå› ã§ã™")
                
                if structure_analysis['has_review_by_client_jp'] == 0:
                    logger.error("âŒ review_by_client_jpãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                    logger.error("  æ­£è§£ã‚¹ã‚³ã‚¢ã®æŠ½å‡ºãŒä¸å¯èƒ½ã§ã™")
                
                if structure_analysis['has_dialogue'] == 0:
                    logger.warning("âš ï¸  dialogueã‚­ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                    logger.warning("  å…ƒã®kokorochatãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒå¤±ã‚ã‚Œã¦ã„ã¾ã™")
                    
        except Exception as e:
            logger.error(f"æ­£è§£ã‚¹ã‚³ã‚¢ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate_score_comparison_csv(self):
        """ã‚¹ã‚³ã‚¢æ¯”è¼ƒç”¨ã®CSVã‚’ç”Ÿæˆ"""
        logger.info("ã‚¹ã‚³ã‚¢æ¯”è¼ƒç”¨ã®CSVã‚’ç”Ÿæˆã—ã¾ã™")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        test_files = list(self.output_dir.glob("test_data_*.jsonl"))
        if not test_files:
            logger.error("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        latest_test_file = max(test_files, key=lambda x: x.stat().st_mtime)
        
        # æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
        results = []
        try:
            with open(latest_test_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    sample = json.loads(line.strip())
                    
                    # æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
                    ground_truth_score = self._extract_ground_truth_score(sample)
                    
                    # äºˆæ¸¬ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡ºï¼ˆç¾åœ¨ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                    predicted_score = self._extract_score_attempt(sample)
                    
                    results.append({
                        'sample_index': i,
                        'ground_truth_score': ground_truth_score,
                        'predicted_score': predicted_score,
                        'error': None if ground_truth_score is not None else "æ­£è§£ã‚¹ã‚³ã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                        'sample_keys': list(sample.keys()),
                        'sample_structure': self._get_sample_structure_summary(sample)
                    })
                    
                    if i >= 100:  # æœ€åˆã®100ã‚µãƒ³ãƒ—ãƒ«ã®ã¿
                        break
        
        except Exception as e:
            logger.error(f"CSVç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        # DataFrameã«å¤‰æ›
        df = pd.DataFrame(results)
        
        # CSVã¨ã—ã¦ä¿å­˜
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        csv_filename = f"score_comparison_{timestamp}.csv"
        csv_path = self.output_dir / csv_filename
        
        df.to_csv(csv_path, index=False, encoding='utf-8')
        logger.info(f"ã‚¹ã‚³ã‚¢æ¯”è¼ƒCSVã‚’ä¿å­˜ã—ã¾ã—ãŸ: {csv_path}")
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        logger.info(f"\n=== ã‚¹ã‚³ã‚¢æ¯”è¼ƒçµ±è¨ˆ ===")
        logger.info(f"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}")
        logger.info(f"æ­£è§£ã‚¹ã‚³ã‚¢ã‚ã‚Š: {df['ground_truth_score'].notna().sum()}")
        logger.info(f"æ­£è§£ã‚¹ã‚³ã‚¢ãªã—: {df['ground_truth_score'].isna().sum()}")
        logger.info(f"äºˆæ¸¬ã‚¹ã‚³ã‚¢ã‚ã‚Š: {df['predicted_score'].notna().sum()}")
        logger.info(f"äºˆæ¸¬ã‚¹ã‚³ã‚¢ãªã—: {df['predicted_score'].isna().sum()}")
        
        # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°
        error_counts = df['error'].value_counts()
        if not error_counts.empty:
            logger.info(f"\nã‚¨ãƒ©ãƒ¼ã®è©³ç´°:")
            for error, count in error_counts.items():
                logger.info(f"  {error}: {count}ã‚µãƒ³ãƒ—ãƒ«")
        
        return csv_path
    
    def _extract_ground_truth_score(self, sample: Dict[str, Any]) -> float:
        """æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡ºï¼ˆkokorochatã®æ­£ã—ã„æ§‹é€ ã«å¯¾å¿œï¼‰"""
        # 1. kokorochatã®æ­£ã—ã„æ§‹é€ ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
        if 'review_by_client_jp' in sample:
            review_data = sample['review_by_client_jp']
            if isinstance(review_data, dict):
                # å„è©•ä¾¡é …ç›®ã®ã‚¹ã‚³ã‚¢ã‚’å–å¾—
                scores = []
                for key, value in review_data.items():
                    if isinstance(value, (int, float)) and 0 <= value <= 5:
                        scores.append(float(value))
                
                if scores:
                    # å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¿”ã™
                    return sum(scores) / len(scores)
        
        # 2. è‹±èªç‰ˆã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚‚ãƒã‚§ãƒƒã‚¯
        if 'review_by_client_en' in sample:
            review_data = sample['review_by_client_en']
            if isinstance(review_data, dict):
                scores = []
                for key, value in review_data.items():
                    if isinstance(value, (int, float)) and 0 <= value <= 5:
                        scores.append(float(value))
                
                if scores:
                    return sum(scores) / len(scores)
        
        # 3. ç›´æ¥çš„ãªã‚¹ã‚³ã‚¢ã‚­ãƒ¼ï¼ˆå¾“æ¥ã®æ–¹æ³•ï¼‰
        direct_score_keys = ['score', 'rating', 'satisfaction', 'evaluation', 'ground_truth']
        for key in direct_score_keys:
            if key in sample:
                try:
                    score = float(sample[key])
                    if 0 <= score <= 5:
                        return score
                except (ValueError, TypeError):
                    continue
        
        # 4. ãƒã‚¹ãƒˆã—ãŸã‚¹ã‚³ã‚¢ã‚­ãƒ¼
        nested_keys = ['metadata', 'annotation', 'label', 'data', 'result']
        for key in nested_keys:
            if key in sample and isinstance(sample[key], dict):
                for sub_key in direct_score_keys:
                    if sub_key in sample[key]:
                        try:
                            score = float(sample[key][sub_key])
                            if 0 <= score <= 5:
                                return score
                        except (ValueError, TypeError):
                            continue
        
        # 5. kokorochatç‰¹æœ‰ã®ã‚­ãƒ¼
        kokorochat_keys = [
            'kokorochat_score', 'kokorochat_rating', 'kokorochat_evaluation',
            'human_score', 'human_rating', 'human_evaluation',
            'expert_score', 'expert_rating', 'expert_evaluation',
            'reference_score', 'reference_rating', 'reference_evaluation'
        ]
        
        for key in kokorochat_keys:
            if key in sample:
                try:
                    score = float(sample[key])
                    if 0 <= score <= 5:
                        return score
                except (ValueError, TypeError):
                    continue
        
        # 6. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã®ã‚¹ã‚³ã‚¢ï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
        if 'messages' in sample:
            messages = sample['messages']
            # æœ€å¾Œã®æ•°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’æ¢ã™
            for msg in reversed(messages[-5:]):
                if msg.get('role') == 'assistant':
                    content = msg.get('content', '')
                    # ã‚¹ã‚³ã‚¢é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€å ´åˆã®ã¿æ•°å€¤ã‚’æ¢ã™
                    score_keywords = ['è©•ä¾¡', 'ã‚¹ã‚³ã‚¢', 'ç‚¹', 'rating', 'score', 'satisfaction']
                    if any(keyword in content for keyword in score_keywords):
                        import re
                        match = re.search(r'(\d+(?:\.\d+)?)', content)
                        if match:
                            try:
                                score = float(match.group(1))
                                if 0 <= score <= 5:
                                    return score
                            except ValueError:
                                continue
        
        return None

    def analyze_test_data_structure(self, max_samples: int = 10):
        """
        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’è©³ç´°åˆ†æ
        
        Args:
            max_samples: åˆ†æã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
        """
        logger.info(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’è©³ç´°åˆ†æã—ã¾ã™ï¼ˆæœ€å¤§{max_samples}ã‚µãƒ³ãƒ—ãƒ«ï¼‰")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        test_files = list(self.output_dir.glob("test_data_*.jsonl"))
        if not test_files:
            logger.error("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        latest_test_file = max(test_files, key=lambda x: x.stat().st_mtime)
        logger.info(f"åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {latest_test_file}")
        
        # ã‚¹ã‚³ã‚¢æ¯”è¼ƒCSVã‚‚èª­ã¿è¾¼ã¿
        csv_files = list(self.output_dir.glob("score_comparison_*.csv"))
        if csv_files:
            latest_csv = max(csv_files, key=lambda x: x.stat().st_mtime)
            score_df = pd.read_csv(latest_csv)
            logger.info(f"ã‚¹ã‚³ã‚¢æ¯”è¼ƒCSV: {latest_csv}")
            logger.info(f"CSVè¡Œæ•°: {len(score_df)}")
        else:
            score_df = None
            logger.warning("ã‚¹ã‚³ã‚¢æ¯”è¼ƒCSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        try:
            with open(latest_test_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if i >= max_samples:
                        break
                    
                    sample = json.loads(line.strip())
                    print(f"\n{'='*80}")
                    print(f"ã‚µãƒ³ãƒ—ãƒ« {i+1} ã®è©³ç´°åˆ†æ")
                    print(f"{'='*80}")
                    
                    # åŸºæœ¬æƒ…å ±
                    print(f"ã‚­ãƒ¼æ•°: {len(sample.keys())}")
                    print(f"ã‚­ãƒ¼ä¸€è¦§: {list(sample.keys())}")
                    
                    # å„ã‚­ãƒ¼ã®è©³ç´°åˆ†æ
                    for key, value in sample.items():
                        self._analyze_key_value(key, value, i+1)
                    
                    # CSVã¨ã®å¯¾å¿œç¢ºèª
                    if score_df is not None and i < len(score_df):
                        csv_row = score_df.iloc[i]
                        print(f"\n--- CSVå¯¾å¿œæƒ…å ± ---")
                        print(f"CSVè¡Œ: {i}")
                        print(f"äºˆæ¸¬ã‚¹ã‚³ã‚¢: {csv_row.get('predicted_score', 'N/A')}")
                        print(f"æ­£è§£ã‚¹ã‚³ã‚¢: {csv_row.get('correct_score', 'N/A')}")
                        print(f"ã‚¨ãƒ©ãƒ¼: {csv_row.get('error', 'N/A')}")
                        
                        # æ­£è§£ã‚¹ã‚³ã‚¢ãŒæ¬ æã—ã¦ã„ã‚‹å ´åˆã®è©³ç´°èª¿æŸ»
                        if pd.isna(csv_row.get('correct_score')):
                            print(f"âš ï¸  æ­£è§£ã‚¹ã‚³ã‚¢ãŒæ¬ æã—ã¦ã„ã¾ã™ï¼")
                            self._investigate_missing_score(sample, i+1)
                    
                    print(f"\n{'='*80}")
                    
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            import traceback
            traceback.print_exc()
    
    def analyze_messages_for_scores(self, max_samples: int = 10):
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æ¢ã™è©³ç´°åˆ†æ
        
        Args:
            max_samples: åˆ†æã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
        """
        logger.info(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æ¢ã™è©³ç´°åˆ†æï¼ˆæœ€å¤§{max_samples}ã‚µãƒ³ãƒ—ãƒ«ï¼‰")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        test_files = list(self.output_dir.glob("test_data_*.jsonl"))
        if not test_files:
            logger.error("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        latest_test_file = max(test_files, key=lambda x: x.stat().st_mtime)
        
        # ã‚¹ã‚³ã‚¢æ¯”è¼ƒCSVã‚‚èª­ã¿è¾¼ã¿
        csv_files = list(self.output_dir.glob("score_comparison_*.csv"))
        if csv_files:
            latest_csv = max(csv_files, key=lambda x: x.stat().st_mtime)
            score_df = pd.read_csv(latest_csv)
        else:
            score_df = None
            logger.warning("ã‚¹ã‚³ã‚¢æ¯”è¼ƒCSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        try:
            with open(latest_test_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if i >= max_samples:
                        break
                    
                    sample = json.loads(line.strip())
                    print(f"\n{'='*80}")
                    print(f"ã‚µãƒ³ãƒ—ãƒ« {i+1} ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è©³ç´°åˆ†æ")
                    print(f"{'='*80}")
                    
                    messages = sample['messages']
                    print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(messages)}")
                    
                    # CSVã®æ­£è§£ã‚¹ã‚³ã‚¢ã‚’å–å¾—
                    csv_score = None
                    if score_df is not None and i < len(score_df):
                        csv_score = score_df.iloc[i].get('correct_score')
                        if not pd.isna(csv_score):
                            print(f"CSVæ­£è§£ã‚¹ã‚³ã‚¢: {csv_score}")
                        else:
                            print(f"CSVæ­£è§£ã‚¹ã‚³ã‚¢: æ¬ æ")
                    
                    # å„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è©³ã—ãåˆ†æ
                    for j, msg in enumerate(messages):
                        role = msg.get('role', 'unknown')
                        content = msg.get('content', '')
                        
                        # ã‚¹ã‚³ã‚¢é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¢ã™
                        score_keywords = ['ç‚¹', 'ã‚¹ã‚³ã‚¢', 'è©•ä¾¡', 'æº€è¶³åº¦', 'rating', 'score', 'satisfaction']
                        has_score_keyword = any(keyword in content for keyword in score_keywords)
                        
                        # æ•°å€¤ã‚’æ¢ã™
                        import re
                        numbers = re.findall(r'\d+(?:\.\d+)?', content)
                        valid_scores = [n for n in numbers if 0 <= float(n) <= 5]
                        
                        # ã‚¹ã‚³ã‚¢é–¢é€£ã®æƒ…å ±ãŒã‚ã‚‹å ´åˆã®ã¿è©³ç´°è¡¨ç¤º
                        if has_score_keyword or valid_scores or len(content) > 200:
                            print(f"\n  ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {j} (role={role}):")
                            print(f"    å†…å®¹: {content[:300]}...")
                            
                            if valid_scores:
                                print(f"    æœ‰åŠ¹ãªã‚¹ã‚³ã‚¢å€™è£œ: {valid_scores}")
                            
                            if has_score_keyword:
                                print(f"    ğŸ” ã‚¹ã‚³ã‚¢é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€")
                            
                            # é•·ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã¯å¾ŒåŠã‚‚ç¢ºèª
                            if len(content) > 300:
                                print(f"    å¾ŒåŠå†…å®¹: {content[-200]}...")
                    
                    # æ­£è§£ã‚¹ã‚³ã‚¢ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ç‰¹åˆ¥èª¿æŸ»
                    if csv_score is None or pd.isna(csv_score):
                        print(f"\nâš ï¸  æ­£è§£ã‚¹ã‚³ã‚¢ãŒæ¬ æã—ã¦ã„ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®ç‰¹åˆ¥èª¿æŸ»:")
                        self._deep_search_for_scores(messages, i+1)
                    
                    print(f"\n{'='*80}")
                    
        except Exception as e:
            logger.error(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            import traceback
            traceback.print_exc()
    
    def analyze_message_structure_for_scores(self, max_samples: int = 5):
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ§‹é€ ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æ¢ã™è©³ç´°åˆ†æ
        
        Args:
            max_samples: åˆ†æã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
        """
        logger.info(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ§‹é€ ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æ¢ã™è©³ç´°åˆ†æï¼ˆæœ€å¤§{max_samples}ã‚µãƒ³ãƒ—ãƒ«ï¼‰")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        test_files = list(self.output_dir.glob("test_data_*.jsonl"))
        if not test_files:
            logger.error("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        latest_test_file = max(test_files, key=lambda x: x.stat().st_mtime)
        
        # ã‚¹ã‚³ã‚¢æ¯”è¼ƒCSVã‚‚èª­ã¿è¾¼ã¿
        csv_files = list(self.output_dir.glob("score_comparison_*.csv"))
        if csv_files:
            latest_csv = max(csv_files, key=lambda x: x.stat().st_mtime)
            score_df = pd.read_csv(latest_csv)
        else:
            score_df = None
        
        try:
            with open(latest_test_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if i >= max_samples:
                        break
                    
                    sample = json.loads(line.strip())
                    print(f"\n{'='*80}")
                    print(f"ã‚µãƒ³ãƒ—ãƒ« {i+1} ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ è©³ç´°åˆ†æ")
                    print(f"{'='*80}")
                    
                    messages = sample['messages']
                    print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(messages)}")
                    
                    # CSVã®æ­£è§£ã‚¹ã‚³ã‚¢ã‚’å–å¾—
                    csv_score = None
                    if score_df is not None and i < len(score_df):
                        csv_score = score_df.iloc[i].get('correct_score')
                        if not pd.isna(csv_score):
                            print(f"CSVæ­£è§£ã‚¹ã‚³ã‚¢: {csv_score}")
                        else:
                            print(f"CSVæ­£è§£ã‚¹ã‚³ã‚¢: æ¬ æ")
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ§‹é€ ã‚’è©³ã—ãåˆ†æ
                    print(f"\n--- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ åˆ†æ ---")
                    
                    # 1. æœ€åˆã®æ•°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    print(f"æœ€åˆã®5ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
                    for j in range(min(5, len(messages))):
                        msg = messages[j]
                        role = msg.get('role', 'unknown')
                        content = msg.get('content', '')
                        print(f"  {j}: role={role}, content={content[:100]}...")
                    
                    # 2. æœ€å¾Œã®æ•°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    print(f"\næœ€å¾Œã®5ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
                    for j in range(max(0, len(messages)-5), len(messages)):
                        msg = messages[j]
                        role = msg.get('role', 'unknown')
                        content = msg.get('content', '')
                        print(f"  {j}: role={role}, content={content[:100]}...")
                    
                    # 3. ç‰¹å®šã®ä½ç½®ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆä¸­é–“ã€3/4ä½ç½®ãªã©ï¼‰
                    if len(messages) > 10:
                        mid_point = len(messages) // 2
                        three_quarter = (len(messages) * 3) // 4
                        
                        print(f"\nä¸­é–“ä½ç½®ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
                        for pos in [mid_point-1, mid_point, mid_point+1]:
                            if 0 <= pos < len(messages):
                                msg = messages[pos]
                                role = msg.get('role', 'unknown')
                                content = msg.get('content', '')
                                print(f"  {pos}: role={role}, content={content[:100]}...")
                        
                        print(f"\n3/4ä½ç½®ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
                        for pos in [three_quarter-1, three_quarter, three_quarter+1]:
                            if 0 <= pos < len(messages):
                                msg = messages[pos]
                                role = msg.get('role', 'unknown')
                                content = msg.get('content', '')
                                print(f"  {pos}: role={role}, content={content[:100]}...")
                    
                    # 4. ã‚¹ã‚³ã‚¢é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¢ã™
                    print(f"\n--- ã‚¹ã‚³ã‚¢é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ ---")
                    score_keywords = ['è©•ä¾¡', 'ã‚¹ã‚³ã‚¢', 'ç‚¹', 'rating', 'score', 'satisfaction', 'æº€è¶³åº¦', 'æ¡ç‚¹']
                    
                    for j, msg in enumerate(messages):
                        content = msg.get('content', '')
                        if any(keyword in content for keyword in score_keywords):
                            role = msg.get('role', 'unknown')
                            print(f"  ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {j} (role={role}): ã‚¹ã‚³ã‚¢é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç™ºè¦‹")
                            print(f"    å†…å®¹: {content[:200]}...")
                    
                    # 5. æ•°å€¤ãŒå«ã¾ã‚Œã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è©³ç´°åˆ†æ
                    print(f"\n--- æ•°å€¤ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è©³ç´°åˆ†æ ---")
                    for j, msg in enumerate(messages):
                        content = msg.get('content', '')
                        import re
                        numbers = re.findall(r'\d+(?:\.\d+)?', content)
                        
                        if numbers:
                            role = msg.get('role', 'unknown')
                            # 0-5ã®ç¯„å›²ã®æ•°å€¤ã®ã¿è¡¨ç¤º
                            valid_scores = [n for n in numbers if 0 <= float(n) <= 5]
                            if valid_scores:
                                print(f"  ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {j} (role={role}):")
                                print(f"    å«ã¾ã‚Œã‚‹æ•°å€¤: {numbers}")
                                print(f"    æœ‰åŠ¹ãªã‚¹ã‚³ã‚¢å€™è£œ: {valid_scores}")
                                print(f"    å†…å®¹: {content[:150]}...")
                    
                    print(f"\n{'='*80}")
                    
        except Exception as e:
            logger.error(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            import traceback
            traceback.print_exc()
    
    def _deep_search_for_scores(self, messages: List[Dict[str, Any]], sample_num: int):
        """ã‚¹ã‚³ã‚¢ã‚’æ·±ãæ¢ã™ç‰¹åˆ¥èª¿æŸ»"""
        print(f"  ã‚µãƒ³ãƒ—ãƒ«{sample_num}ã®æ·±å±¤èª¿æŸ»:")
        
        # æœ€å¾Œã®æ•°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è©³ã—ãèª¿ã¹ã‚‹
        last_messages = messages[-10:] if len(messages) >= 10 else messages
        
        for j, msg in enumerate(last_messages):
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            
            # æ•°å€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            import re
            all_numbers = re.findall(r'\d+(?:\.\d+)?', content)
            
            if all_numbers:
                print(f"    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {len(messages)-len(last_messages)+j} (role={role}):")
                print(f"      å«ã¾ã‚Œã‚‹æ•°å€¤: {all_numbers}")
                
                # 0-5ã®ç¯„å›²ã®æ•°å€¤ã‚’ãƒã‚§ãƒƒã‚¯
                valid_scores = [n for n in all_numbers if 0 <= float(n) <= 5]
                if valid_scores:
                    print(f"      æœ‰åŠ¹ãªã‚¹ã‚³ã‚¢å€™è£œ: {valid_scores}")
                
                # ã‚¹ã‚³ã‚¢é–¢é€£ã®æ–‡è„ˆã‚’ç¢ºèª
                if any(keyword in content for keyword in ['ç‚¹', 'ã‚¹ã‚³ã‚¢', 'è©•ä¾¡', 'æº€è¶³åº¦']):
                    print(f"      ğŸ” ã‚¹ã‚³ã‚¢é–¢é€£ã®æ–‡è„ˆã‚’å«ã‚€")
                    print(f"      å†…å®¹: {content[:200]}...")
    
    def _analyze_key_value(self, key: str, value: Any, sample_num: int):
        """ã‚­ãƒ¼ã¨å€¤ã®è©³ç´°åˆ†æ"""
        print(f"\nã€{key}ã€‘")
        print(f"  å‹: {type(value).__name__}")
        
        if isinstance(value, dict):
            print(f"  è¾æ›¸ã‚µã‚¤ã‚º: {len(value)}å€‹ã®ã‚­ãƒ¼")
            print(f"  ã‚­ãƒ¼ä¸€è¦§: {list(value.keys())}")
            
            # é‡è¦ãªã‚­ãƒ¼ã®å†…å®¹ã‚’è©³ç´°è¡¨ç¤º
            if key in ['review', 'evaluation', 'score', 'rating', 'annotation', 'metadata']:
                print(f"  å†…å®¹:")
                for sub_key, sub_value in value.items():
                    if isinstance(sub_value, (int, float)):
                        print(f"    {sub_key}: {sub_value}")
                    elif isinstance(sub_value, str):
                        print(f"    {sub_key}: {sub_value[:100]}...")
                    else:
                        print(f"    {sub_key}: {type(sub_value).__name__}")
        
        elif isinstance(value, list):
            print(f"  ãƒªã‚¹ãƒˆã‚µã‚¤ã‚º: {len(value)}å€‹ã®è¦ç´ ")
            
            if key == 'messages':
                print(f"  ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è©³ç´°:")
                for j, msg in enumerate(value[:5]):  # æœ€åˆã®5ã¤
                    role = msg.get('role', 'unknown')
                    content = msg.get('content', '')
                    print(f"    {j}: role={msg.get('role')}")
                    print(f"      content: {msg.get('content', '')[:200]}...")
                
                if len(value) > 5:
                    print(f"    ... ä»– {len(value)-5}å€‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
            
            elif key in ['annotations', 'evaluations', 'scores']:
                print(f"  å†…å®¹ï¼ˆæœ€åˆã®3ã¤ï¼‰:")
                for j, item in enumerate(value[:3]):
                    if isinstance(item, dict):
                        print(f"    {j}: {list(item.keys())}")
                    else:
                        print(f"    {j}: {item}")
        
        elif isinstance(value, (int, float)):
            print(f"  å€¤: {value}")
            if key.lower() in ['score', 'rating', 'satisfaction', 'evaluation']:
                print(f"  â­ ã‚¹ã‚³ã‚¢é–¢é€£ã®å¯èƒ½æ€§ãŒé«˜ã„ï¼")
        
        elif isinstance(value, str):
            print(f"  å€¤: {value[:200]}...")
            # æ•°å€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            import re
            numbers = re.findall(r'\d+(?:\.\d+)?', value)
            if numbers:
                print(f"  å«ã¾ã‚Œã‚‹æ•°å€¤: {numbers}")
                # 0-5ã®ç¯„å›²ã®æ•°å€¤ã‚’ãƒã‚§ãƒƒã‚¯
                valid_scores = [n for n in numbers if 0 <= float(n) <= 5]
                if valid_scores:
                    print(f"  æœ‰åŠ¹ãªã‚¹ã‚³ã‚¢å€™è£œ: {valid_scores}")
    
    def _investigate_missing_score(self, sample: Dict[str, Any], sample_num: int):
        """æ­£è§£ã‚¹ã‚³ã‚¢ãŒæ¬ æã—ã¦ã„ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®è©³ç´°èª¿æŸ»"""
        print(f"\nğŸ” æ­£è§£ã‚¹ã‚³ã‚¢æ¬ æã®åŸå› èª¿æŸ»ï¼ˆã‚µãƒ³ãƒ—ãƒ«{sample_num}ï¼‰")
        
        # æ•°å€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ã‚­ãƒ¼ã‚’æ¢ã™
        potential_scores = []
        
        for key, value in sample.items():
            if isinstance(value, (int, float)):
                if 0 <= value <= 5:
                    potential_scores.append((key, value, "ç›´æ¥çš„ãªæ•°å€¤"))
            
            elif isinstance(value, str):
                import re
                numbers = re.findall(r'\d+(?:\.\d+)?', value)
                for num in numbers:
                    if 0 <= float(num) <= 5:
                        potential_scores.append((key, float(num), f"æ–‡å­—åˆ—å†…ã®æ•°å€¤: {value[:50]}..."))
            
            elif isinstance(value, dict):
                for sub_key, sub_value in value.items():
                    if isinstance(sub_value, (int, float)) and 0 <= sub_value <= 5:
                        potential_scores.append((f"{key}.{sub_key}", sub_value, "ãƒã‚¹ãƒˆã—ãŸæ•°å€¤"))
        
        if potential_scores:
            print(f"  ğŸ¯ ã‚¹ã‚³ã‚¢å€™è£œã‚’ç™ºè¦‹:")
            for key, score, reason in potential_scores:
                print(f"    {key}: {score} ({reason})")
        else:
            print(f"  âŒ ã‚¹ã‚³ã‚¢å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ã‚µãƒ³ãƒ—ãƒ«ã®å…¨ä½“çš„ãªæ§‹é€ ã‚’å†ç¢ºèª
        print(f"\n  ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«å…¨ä½“ã®æ§‹é€ :")
        for key, value in sample.items():
            if isinstance(value, dict):
                print(f"    {key}: {list(value.keys())}")
            elif isinstance(value, list):
                print(f"    {key}: {len(value)}å€‹ã®è¦ç´ ")
            else:
                print(f"    {key}: {type(value).__name__}")
    
    def analyze_score_extraction_patterns(self):
        """æ­£è§£ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æï¼ˆkokorochatã®æ­£ã—ã„æ§‹é€ ã«å¯¾å¿œï¼‰"""
        logger.info("æ­£è§£ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã¾ã™")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        test_files = list(self.output_dir.glob("test_data_*.jsonl"))
        if not test_files:
            logger.error("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        latest_test_file = max(test_files, key=lambda x: x.stat().st_mtime)
        
        # å…ƒã®kokorochatãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç¢ºèª
        original_files = list(self.output_dir.glob("*kokorochat*.jsonl"))
        
        # æˆåŠŸãƒ»å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        success_patterns = []
        failure_patterns = []
        
        try:
            with open(latest_test_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if i >= 50:  # æœ€åˆã®50ã‚µãƒ³ãƒ—ãƒ«ã®ã¿
                        break
                    
                    sample = json.loads(line.strip())
                    
                    # æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡ºã—ã¦ã¿ã‚‹
                    score = self._extract_score_attempt(sample)
                    
                    if score is not None:
                        success_patterns.append({
                            'sample_index': i,
                            'score': score,
                            'keys': list(sample.keys()),
                            'structure': self._get_sample_structure_summary(sample)
                        })
                    else:
                        failure_patterns.append({
                            'sample_index': i,
                            'keys': list(sample.keys()),
                            'structure': self._get_sample_structure_summary(sample)
                        })
        
        except Exception as e:
            logger.error(f"ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        # çµæœã‚’è¡¨ç¤º
        print(f"\n{'='*80}")
        print(f"æ­£è§£ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æçµæœ")
        print(f"{'='*80}")
        
        print(f"\nâœ… æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: {len(success_patterns)}ã‚µãƒ³ãƒ—ãƒ«")
        for pattern in success_patterns[:5]:  # æœ€åˆã®5ã¤
            print(f"  ã‚µãƒ³ãƒ—ãƒ«{pattern['sample_index']}: ã‚¹ã‚³ã‚¢{pattern['score']}")
            print(f"    ã‚­ãƒ¼: {pattern['keys']}")
            print(f"    æ§‹é€ : {pattern['structure']}")
        
        print(f"\nâŒ å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(failure_patterns)}ã‚µãƒ³ãƒ—ãƒ«")
        for pattern in failure_patterns[:5]:  # æœ€åˆã®5ã¤
            print(f"  ã‚µãƒ³ãƒ—ãƒ«{pattern['sample_index']}")
            print(f"    ã‚­ãƒ¼: {pattern['keys']}")
            print(f"    æ§‹é€ : {pattern['structure']}")
        
        # æˆåŠŸãƒ»å¤±æ•—ã®å‚¾å‘åˆ†æ
        if success_patterns:
            print(f"\nğŸ“Š æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‚¾å‘:")
            common_keys = set.intersection(*[set(p['keys']) for p in success_patterns])
            print(f"  å…±é€šã‚­ãƒ¼: {common_keys}")
        
        if failure_patterns:
            print(f"\nğŸ“Š å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‚¾å‘:")
            missing_keys = set.intersection(*[set(p['keys']) for p in failure_patterns])
            print(f"  å…±é€šã‚­ãƒ¼: {missing_keys}")
        
        # å…ƒã®kokorochatãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒ
        if original_files:
            print(f"\n{'='*80}")
            print(f"å…ƒã®kokorochatãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒ")
            print(f"{'='*80}")
            
            try:
                with open(original_files[0], 'r', encoding='utf-8') as f:
                    original_sample = json.loads(f.readline().strip())
                    print(f"å…ƒã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ : {list(original_sample.keys())}")
                    
                    if 'review_by_client_jp' in original_sample:
                        review_data = original_sample['review_by_client_jp']
                        print(f"è©•ä¾¡é …ç›®æ•°: {len(review_data)}")
                        print(f"è©•ä¾¡é …ç›®ä¾‹:")
                        for i, (key, value) in enumerate(review_data.items()):
                            if i < 5:  # æœ€åˆã®5é …ç›®
                                print(f"  {key}: {value}")
                            else:
                                break
                        
                        # ã‚¹ã‚³ã‚¢ã®çµ±è¨ˆ
                        scores = [v for v in review_data.values() if isinstance(v, (int, float))]
                        if scores:
                            print(f"ã‚¹ã‚³ã‚¢çµ±è¨ˆ:")
                            print(f"  æœ€å°å€¤: {min(scores)}")
                            print(f"  æœ€å¤§å€¤: {max(scores)}")
                            print(f"  å¹³å‡å€¤: {sum(scores)/len(scores):.2f}")
                            print(f"  ã‚¹ã‚³ã‚¢ç¯„å›²: 0-5ã®ç¯„å›²å†…" if all(0 <= s <= 5 for s in scores) else "ã‚¹ã‚³ã‚¢ç¯„å›²: 0-5ã®ç¯„å›²å¤–")
                    
                    if 'dialogue' in original_sample:
                        dialogue = original_sample['dialogue']
                        print(f"å¯¾è©±ãƒ‡ãƒ¼ã‚¿: {len(dialogue)}å€‹ã®ã‚¿ãƒ¼ãƒ³")
                    
                    if 'topic' in original_sample:
                        topic = original_sample['topic']
                        print(f"ãƒˆãƒ”ãƒƒã‚¯: {topic}")
                
            except Exception as e:
                print(f"å…ƒã®ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        
        # å•é¡Œã®ç‰¹å®šã¨è§£æ±ºç­–
        print(f"\n{'='*80}")
        print(f"å•é¡Œã®ç‰¹å®šã¨è§£æ±ºç­–")
        print(f"{'='*80}")
        
        if failure_patterns:
            print(f"âŒ å•é¡Œ: {len(failure_patterns)}ã‚µãƒ³ãƒ—ãƒ«ã§æ­£è§£ã‚¹ã‚³ã‚¢ã®æŠ½å‡ºã«å¤±æ•—")
            print(f"   åŸå› : ãƒ‡ãƒ¼ã‚¿å¤‰æ›æ™‚ã«review_by_client_jpãŒå¤±ã‚ã‚Œã¦ã„ã‚‹")
            print(f"   å½±éŸ¿: ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ãŒä¸å¯èƒ½")
            
            print(f"\nğŸ’¡ è§£æ±ºç­–:")
            print(f"   1. ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä¿®æ­£")
            print(f"      - review_by_client_jpã‚’ä¿æŒã™ã‚‹")
            print(f"      - dialogueã‚’messagesã«å¤‰æ›ã™ã‚‹éš›ã®å‡¦ç†ã‚’ç¢ºèª")
            print(f"   2. æ­£è§£ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ã®ä¿®æ­£")
            print(f"      - review_by_client_jpã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º")
            print(f"      - å„è©•ä¾¡é …ç›®ã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—")
            print(f"   3. ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç¢ºèª")
            print(f"      - å¤‰æ›å‰å¾Œã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’æ¯”è¼ƒ")
            print(f"      - æ­£è§£ã‚¹ã‚³ã‚¢ã®ç¯„å›²ï¼ˆ0-5ï¼‰ã‚’ç¢ºèª")
        else:
            print(f"âœ… å•é¡Œãªã—: ã™ã¹ã¦ã®ã‚µãƒ³ãƒ—ãƒ«ã§æ­£è§£ã‚¹ã‚³ã‚¢ã®æŠ½å‡ºã«æˆåŠŸ")
    
    def _extract_score_attempt(self, sample: Dict[str, Any]) -> float:
        """ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡ºã—ã¦ã¿ã‚‹ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        # è¤‡æ•°ã®æ–¹æ³•ã§ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
        methods = [
            self._extract_from_messages,
            self._extract_from_metadata,
            self._extract_from_content,
            self._extract_from_annotations,
            self._extract_from_kokorochat_specific
        ]
        
        for method in methods:
            try:
                score = method(sample)
                if score is not None:
                    return score
            except:
                continue
        
        return None
    
    def _get_sample_structure_summary(self, sample: Dict[str, Any]) -> str:
        """ã‚µãƒ³ãƒ—ãƒ«ã®æ§‹é€ ã‚’ç°¡æ½”ã«è¦ç´„"""
        summary = []
        for key, value in sample.items():
            if isinstance(value, dict):
                summary.append(f"{key}(dict:{len(value)})")
            elif isinstance(value, list):
                summary.append(f"{key}(list:{len(value)})")
            else:
                summary.append(f"{key}({type(value).__name__})")
        return ", ".join(summary)
    
    # æ—¢å­˜ã®æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆanalyze_finetuned_model.pyã‹ã‚‰ã‚³ãƒ”ãƒ¼ï¼‰
    def _extract_from_messages(self, sample: Dict[str, Any]) -> float:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º"""
        if 'messages' not in sample:
            return None
        
        messages = sample['messages']
        
        # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’æ¢ã™
        for msg in reversed(messages):
            if msg.get('role') == 'assistant':
                content = msg.get('content', '')
                # æ•°å€¤ã‚¹ã‚³ã‚¢ã‚’æ¢ã™
                import re
                match = re.search(r'(\d+(?:\.\d+)?)', content)
                if match:
                    score = float(match.group(1))
                    if 0 <= score <= 5:
                        return score
        
        return None
    
    def _extract_from_metadata(self, sample: Dict[str, Any]) -> float:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º"""
        if 'metadata' not in sample:
            return None
        
        metadata = sample['metadata']
        
        # ã‚¹ã‚³ã‚¢é–¢é€£ã®ã‚­ãƒ¼ã‚’æ¢ã™
        score_keys = ['score', 'rating', 'satisfaction', 'evaluation']
        for key in score_keys:
            if key in metadata:
                try:
                    score = float(metadata[key])
                    if 0 <= score <= 5:
                        return score
                except (ValueError, TypeError):
                    continue
        
        return None
    
    def _extract_from_content(self, sample: Dict[str, Any]) -> float:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º"""
        # ã‚µãƒ³ãƒ—ãƒ«å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’æ¢ã™
        sample_text = json.dumps(sample, ensure_ascii=False)
        
        # æ•°å€¤ã‚¹ã‚³ã‚¢ã‚’æ¢ã™
        import re
        matches = re.findall(r'(\d+(?:\.\d+)?)', sample_text)
        for match in matches:
            try:
                score = float(match)
                if 0 <= score <= 5:
                    return score
            except ValueError:
                continue
        
        return None
    
    def _extract_from_annotations(self, sample: Dict[str, Any]) -> float:
        """ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º"""
        annotation_keys = ['annotation', 'label', 'ground_truth', 'reference']
        
        for key in annotation_keys:
            if key in sample:
                annotation = sample[key]
                if isinstance(annotation, dict):
                    # ã‚¹ã‚³ã‚¢é–¢é€£ã®ã‚­ãƒ¼ã‚’æ¢ã™
                    score_keys = ['score', 'rating', 'satisfaction', 'evaluation']
                    for score_key in score_keys:
                        if score_key in annotation:
                            try:
                                score = float(annotation[score_key])
                                if 0 <= score <= 5:
                                    return score
                            except (ValueError, TypeError):
                                continue
                elif isinstance(annotation, (int, float)):
                    if 0 <= annotation <= 5:
                        return float(annotation)
        
        return None
    
    def _extract_from_kokorochat_specific(self, sample: Dict[str, Any]) -> float:
        """kokorochatç‰¹æœ‰ã®æ§‹é€ ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º"""
        # kokorochatã§ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚­ãƒ¼ã‚’æ¢ã™
        kokorochat_keys = [
            'kokorochat_score', 'kokorochat_rating', 'kokorochat_evaluation',
            'ground_truth_score', 'ground_truth_rating', 'ground_truth_evaluation',
            'human_score', 'human_rating', 'human_evaluation',
            'expert_score', 'expert_rating', 'expert_evaluation',
            'reference_score', 'reference_rating', 'reference_evaluation'
        ]
        
        for key in kokorochat_keys:
            if key in sample:
                try:
                    score = float(sample[key])
                    if 0 <= score <= 5:
                        return score
                except (ValueError, TypeError):
                    continue
        
        # ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã‚‚æ¢ã™
        for key in ['data', 'annotation', 'evaluation', 'score']:
            if key in sample and isinstance(sample[key], dict):
                for sub_key in kokorochat_keys:
                    if sub_key in sample[key]:
                        try:
                            score = float(sample[key][sub_key])
                            if 0 <= score <= 5:
                                return score
                        except (ValueError, TypeError):
                            continue
        
        return None

    def _identify_data_conversion_issues(self):
        """ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®å•é¡Œã‚’ç‰¹å®š"""
        logger.info("\n=== ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®å•é¡Œç‰¹å®š ===")
        
        # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¨å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒ
        original_files = list(self.output_dir.glob("*kokorochat*.jsonl"))
        converted_files = list(self.output_dir.glob("train_data_*.jsonl"))
        
        if original_files and converted_files:
            logger.info("ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®å‰å¾Œã‚’æ¯”è¼ƒã—ã¾ã™")
            
            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’ç¢ºèª
            original_structure = self._get_file_structure_summary(original_files[0])
            logger.info(f"å…ƒã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ : {original_structure}")
            
            # å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’ç¢ºèª
            converted_structure = self._get_file_structure_summary(converted_files[0])
            logger.info(f"å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ : {converted_structure}")
            
            # å•é¡Œã®ç‰¹å®š
            if 'review_by_client_jp' in original_structure and 'review_by_client_jp' not in converted_structure:
                logger.error("âŒ é‡å¤§ãªå•é¡Œ: review_by_client_jpãŒå¤‰æ›ã§å¤±ã‚ã‚Œã¦ã„ã¾ã™")
                logger.error("  ã“ã‚ŒãŒæ­£è§£ã‚¹ã‚³ã‚¢ãŒæŠ½å‡ºã§ããªã„ç›´æ¥ã®åŸå› ã§ã™")
            
            if 'dialogue' in original_structure and 'dialogue' not in converted_structure:
                logger.warning("âš ï¸  dialogueã‚­ãƒ¼ãŒå¤‰æ›ã§å¤±ã‚ã‚Œã¦ã„ã¾ã™")
                logger.warning("  å…ƒã®ä¼šè©±æ§‹é€ ãŒå¤±ã‚ã‚Œã¦ã„ã¾ã™")
            
            if 'topic' in original_structure and 'topic' not in converted_structure:
                logger.warning("âš ï¸  topicã‚­ãƒ¼ãŒå¤‰æ›ã§å¤±ã‚ã‚Œã¦ã„ã¾ã™")
                logger.warning("  ãƒˆãƒ”ãƒƒã‚¯æƒ…å ±ãŒå¤±ã‚ã‚Œã¦ã„ã¾ã™")
            
            # æ¨å¥¨ã•ã‚Œã‚‹ä¿®æ­£æ–¹æ³•
            logger.info("\n--- æ¨å¥¨ã•ã‚Œã‚‹ä¿®æ­£æ–¹æ³• ---")
            logger.info("1. ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§review_by_client_jpã‚’ä¿æŒã™ã‚‹")
            logger.info("2. dialogueã‚­ãƒ¼ã‚’messagesã«å¤‰æ›ã™ã‚‹éš›ã®å‡¦ç†ã‚’ç¢ºèªã™ã‚‹")
            logger.info("3. æ­£è§£ã‚¹ã‚³ã‚¢ã®æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ã‚’ä¿®æ­£ã™ã‚‹")
        
        else:
            logger.warning("å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æ¯”è¼ƒã§ãã¾ã›ã‚“")
    
    def _get_file_structure_summary(self, file_path: Path) -> Dict[str, int]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’è¦ç´„"""
        structure_summary = {}
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if i >= 10:  # æœ€åˆã®10ã‚µãƒ³ãƒ—ãƒ«ã®ã¿
                        break
                    
                    sample = json.loads(line.strip())
                    for key in sample.keys():
                        if key not in structure_summary:
                            structure_summary[key] = 0
                        structure_summary[key] += 1
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        
        return structure_summary

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
    output_dir = "openai_sft_outputs"
    if not os.path.exists(output_dir):
        logger.error(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {output_dir} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return
    
    # åˆ†æå™¨ã‚’åˆæœŸåŒ–
    analyzer = TestDataStructureAnalyzer(output_dir)
    
    # 1. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼
    logger.info("=== ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å¦¥å½“æ€§æ¤œè¨¼ ===")
    analyzer.validate_data_structure()
    
    # 2. ã‚¹ã‚³ã‚¢æ¯”è¼ƒç”¨ã®CSVã‚’ç”Ÿæˆ
    logger.info("\n=== ã‚¹ã‚³ã‚¢æ¯”è¼ƒç”¨CSVã®ç”Ÿæˆ ===")
    csv_path = analyzer.generate_score_comparison_csv()
    
    # 3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’è©³ç´°åˆ†æ
    logger.info("\n=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ è©³ç´°åˆ†æ ===")
    analyzer.analyze_test_data_structure(max_samples=5)
    
    # 4. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æ¢ã™è©³ç´°åˆ†æ
    logger.info("\n=== ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æ¢ã™è©³ç´°åˆ†æ ===")
    analyzer.analyze_messages_for_scores(max_samples=5)
    
    # 5. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ§‹é€ ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æ¢ã™è©³ç´°åˆ†æ
    logger.info("\n=== ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ§‹é€ ã‹ã‚‰æ­£è§£ã‚¹ã‚³ã‚¢ã‚’æ¢ã™è©³ç´°åˆ†æ ===")
    analyzer.analyze_message_structure_for_scores(max_samples=5)
    
    # 6. æ­£è§£ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
    logger.info("\n=== æ­£è§£ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ ===")
    analyzer.analyze_score_extraction_patterns()

if __name__ == "__main__":
    main()