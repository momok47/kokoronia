import os
import json
import torch
import numpy as np
from typing import Dict, List, Optional, Tuple
from datasets import load_dataset, Dataset
import logging
import random

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# 17é …ç›®ã®è©•ä¾¡æŒ‡æ¨™
EVALUATION_ITEMS = [
    "è´ã„ã¦ã‚‚ã‚‰ãˆãŸã€ã‚ã‹ã£ã¦ã‚‚ã‚‰ãˆãŸã¨æ„Ÿã˜ãŸ",
    "å°Šé‡ã•ã‚ŒãŸã¨æ„Ÿã˜ãŸ",
    "æ–°ã—ã„æ°—ã¥ãã‚„ä½“é¨“ãŒã‚ã£ãŸ",
    "å¸Œæœ›ã‚„æœŸå¾…ã‚’æ„Ÿã˜ã‚‰ã‚ŒãŸ",
    "å–ã‚Šçµ„ã¿ãŸã‹ã£ãŸã“ã¨ã‚’æ‰±ãˆãŸ",
    "ä¸€ç·’ã«è€ƒãˆãªãŒã‚‰å–ã‚Šçµ„ã‚ãŸ",
    "ã‚„ã‚Šã¨ã‚Šã®ãƒªã‚ºãƒ ãŒã‚ã£ã¦ã„ãŸ",
    "å±…å¿ƒåœ°ã®ã‚ˆã„ã‚„ã‚Šã¨ã‚Šã ã£ãŸ",
    "å…¨ä½“ã¨ã—ã¦é©åˆ‡ã§ã‚ˆã‹ã£ãŸ",
    "ä»Šå›ã®ç›¸è«‡ã¯ä¾¡å€¤ãŒã‚ã£ãŸ",
    "ç›¸è«‡é–‹å§‹ã®å††æ»‘ã•",
    "ç›¸è«‡çµ‚äº†ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼ˆä¸å¿…è¦ã«è´ãã™ãã¦ã„ãªã„ã‹ï¼‰ã€å††æ»‘ã•",
    "å—å®¹ãƒ»å…±æ„Ÿ",
    "è‚¯å®šãƒ»æ‰¿èª",
    "çš„ç¢ºãªè³ªå•ã«ã‚ˆã‚‹ä¼šè©±ã®ä¿ƒé€²",
    "è¦ç´„",
    "å•é¡Œã®æ˜ç¢ºåŒ–",
    "ã“ã®ç›¸è«‡ã§ã®ç›®æ¨™ã®æ˜ç¢ºåŒ–",
    "æ¬¡ã®è¡Œå‹•ã«ã¤ãªãŒã‚‹ææ¡ˆ",
    "å‹‡æ°—ã¥ã‘ãƒ»å¸Œæœ›ã®å–šèµ·"
]

def load_and_split_dataset():
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã€8:1:1ã«åˆ†å‰²"""
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
    ds = load_dataset("UEC-InabaLab/KokoroChat")
    df_all = ds['train']

    print("=== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ± ===")
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(df_all)}")
    print(f"ã‚«ãƒ©ãƒ : {df_all.column_names}")

    # train:test:valid = 8:1:1 ã«åˆ†å‰²
    print("\n=== ãƒ‡ãƒ¼ã‚¿åˆ†å‰² ===")
    total_size = len(df_all)
    indices = list(range(total_size))
    random.shuffle(indices)

    train_end = int(total_size * 0.8)
    test_end = int(total_size * 0.9)

    train_indices = indices[:train_end]
    test_indices = indices[train_end:test_end]
    valid_indices = indices[test_end:]

    train_data = df_all.select(train_indices)
    test_data = df_all.select(test_indices)
    valid_data = df_all.select(valid_indices)

    print(f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(train_data)} ({len(train_data)/total_size*100:.1f}%)")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(test_data)} ({len(test_data)/total_size*100:.1f}%)")
    print(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(valid_data)} ({len(valid_data)/total_size*100:.1f}%)")

    return train_data, test_data, valid_data

def calculate_weighted_average(turn_scores: list) -> float:
    """ã‚¿ãƒ¼ãƒ³ã‚¹ã‚³ã‚¢ã®åŠ é‡å¹³å‡ã‚’è¨ˆç®—"""
    if not turn_scores:
        raise ValueError("ã‚¿ãƒ¼ãƒ³ã‚¹ã‚³ã‚¢ãƒªã‚¹ãƒˆãŒç©ºã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    # å¾ŒåŠã®ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚Šé‡ã¿ã‚’ä»˜ã‘ã‚‹ï¼ˆä¼šè©±ã®é€²è¡Œã«å¿œã˜ã¦ï¼‰
    weights = []
    for i in range(len(turn_scores)):
        weight = 1.0 + (i * 0.2)
        weights.append(weight)
    
    # æ­£è¦åŒ–
    total_weight = sum(weights)
    normalized_weights = [w / total_weight for w in weights]
    
    # åŠ é‡å¹³å‡ã‚’è¨ˆç®—
    weighted_average = sum(score * weight for score, weight in zip(turn_scores, normalized_weights))
    return weighted_average

def calculate_weighted_average_probabilities(turn_probabilities: List[List[float]]) -> List[float]:
    """
    ç¢ºç‡åˆ†å¸ƒã®åŠ é‡å¹³å‡ã‚’è¨ˆç®—
    
    Args:
        turn_probabilities: å„ã‚¿ãƒ¼ãƒ³ã®ç¢ºç‡åˆ†å¸ƒã®ãƒªã‚¹ãƒˆ
                          [[p0, p1, p2, p3, p4, p5], ...]
    
    Returns:
        åŠ é‡å¹³å‡ã•ã‚ŒãŸç¢ºç‡åˆ†å¸ƒ [p0, p1, p2, p3, p4, p5]
    """
    if not turn_probabilities:
        # ç©ºã®å ´åˆã¯å‡ç­‰ãªç¢ºç‡åˆ†å¸ƒã‚’è¿”ã™ãªã©ã€é©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        return [1/6] * 6

    # å¾ŒåŠã®ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚Šé‡ã¿ã‚’ä»˜ã‘ã‚‹ï¼ˆä¼šè©±ã®é€²è¡Œã«å¿œã˜ã¦ï¼‰
    weights = [1.0 + (i * 0.2) for i in range(len(turn_probabilities))]
    
    # æ­£è¦åŒ–
    total_weight = sum(weights)
    if total_weight == 0:
        # é‡ã¿ã®åˆè¨ˆãŒ0ã«ãªã‚‹ã“ã¨ã¯é€šå¸¸ãªã„ãŒã€å¿µã®ãŸã‚å‡ç­‰ãªé‡ã¿ã«
        normalized_weights = [1/len(weights)] * len(weights)
    else:
        normalized_weights = [w / total_weight for w in weights]
    
    # å„ã‚¹ã‚³ã‚¢ï¼ˆ0-5ï¼‰ã«ã¤ã„ã¦åŠ é‡å¹³å‡ã‚’è¨ˆç®—
    weighted_probabilities = [0.0] * 6
    
    for score_idx in range(6):
        for turn_idx, turn_probs in enumerate(turn_probabilities):
            if len(turn_probs) > score_idx:
                weighted_probabilities[score_idx] += turn_probs[score_idx] * normalized_weights[turn_idx]
    
    # ç¢ºç‡ã®åˆè¨ˆã‚’1.0ã«æ­£è¦åŒ–
    total_prob = sum(weighted_probabilities)
    if total_prob > 0:
        weighted_probabilities = [p / total_prob for p in weighted_probabilities]
    else:
        # ğŸš¨ã€é‡è¦ã€‘åˆè¨ˆãŒ0ã®å ´åˆã€å‡ç­‰ãªç¢ºç‡åˆ†å¸ƒã‚’è¿”ã™
        logger.warning("åŠ é‡å¹³å‡å¾Œã®ç¢ºç‡åˆè¨ˆãŒ0ã§ã—ãŸã€‚å‡ç­‰åˆ†å¸ƒã‚’è¿”ã—ã¾ã™ã€‚")
        weighted_probabilities = [1/6] * 6
    
    return weighted_probabilities

def probability_to_expected_score(probabilities: List[float]) -> float:
    """
    ç¢ºç‡åˆ†å¸ƒã‹ã‚‰æœŸå¾…å€¤ã‚’è¨ˆç®—
    Args:
        probabilities: [p0, p1, p2, p3, p4, p5]
    
    Returns:
        æœŸå¾…å€¤ã‚¹ã‚³ã‚¢ (0.0-5.0)
    """
    expected_score = sum(i * p for i, p in enumerate(probabilities))
    return expected_score 