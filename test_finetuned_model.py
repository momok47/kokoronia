#!/usr/bin/env python3
"""
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸGPT-4o miniãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ¢ãƒ‡ãƒ«ID: ft:gpt-4o-mini-2024-07-18:personal::CAJ6PxFB
"""

import os
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
import json

def load_environment():
    """ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿"""
    project_root = Path(__file__).parent
    env_path = project_root / ".env"
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ… .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {env_path}")
    else:
        print(f"âŒ .envãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {env_path}")
        return False
    
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    
    return True

def test_finetuned_model():
    """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    if not load_environment():
        return
    
    # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ID
    model_id = "ft:gpt-4o-mini-2024-07-18:personal::CAJ6PxFB"
    
    print(f"\nğŸ¤– ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
    print(f"ãƒ¢ãƒ‡ãƒ«ID: {model_id}")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ç›¸è«‡ã‚·ãƒŠãƒªã‚ª
    test_scenarios = [
        {
            "name": "ä»•äº‹ã®ã‚¹ãƒˆãƒ¬ã‚¹ç›¸è«‡",
            "messages": [
                {"role": "user", "content": "ã“ã‚“ã«ã¡ã¯ã€‚æœ€è¿‘ä»•äº‹ã§ã¨ã¦ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æ„Ÿã˜ã¦ã„ã¦ã€ç›¸è«‡ã—ãŸã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚"},
                {"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ã€‚ãŠå¿™ã—ã„ä¸­ã€ç›¸è«‡ã«ã„ã‚‰ã—ã¦ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ä»•äº‹ã§ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æ„Ÿã˜ã¦ã„ã‚‰ã£ã—ã‚ƒã‚‹ã®ã§ã™ã­ã€‚ã©ã®ã‚ˆã†ãªçŠ¶æ³ã§ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æ„Ÿã˜ã¦ã„ã‚‹ã‹ã€ãŠè©±ã—ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ"},
                {"role": "user", "content": "ä¸Šå¸ã¨ã®é–¢ä¿‚ãŒã†ã¾ãã„ã‹ãªãã¦ã€æ¯æ—¥ä¼šç¤¾ã«è¡Œãã®ãŒè¾›ã„ã§ã™ã€‚"}
            ]
        },
        {
            "name": "äººé–“é–¢ä¿‚ã®æ‚©ã¿",
            "messages": [
                {"role": "user", "content": "å‹é”ã¨ã®é–¢ä¿‚ã§æ‚©ã‚“ã§ã„ã¾ã™ã€‚ã©ã†ã—ãŸã‚‰ã„ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ"}
            ]
        },
        {
            "name": "è‡ªä¿¡å–ªå¤±ã®ç›¸è«‡",
            "messages": [
                {"role": "user", "content": "æœ€è¿‘ä½•ã‚’ã‚„ã£ã¦ã‚‚ã†ã¾ãã„ã‹ãªãã¦ã€è‡ªåˆ†ã«è‡ªä¿¡ãŒæŒã¦ã¾ã›ã‚“ã€‚"}
            ]
        }
    ]
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª {i}: {scenario['name']}")
        print("-" * 40)
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§å¿œç­”ç”Ÿæˆ
            response = client.chat.completions.create(
                model=model_id,
                messages=scenario["messages"],
                max_tokens=500,
                temperature=0.7,
                top_p=0.9
            )
            
            # å¿œç­”ã‚’è¡¨ç¤º
            assistant_response = response.choices[0].message.content
            print(f"ğŸ‘¤ ç›¸è«‡è€…: {scenario['messages'][-1]['content']}")
            print(f"ğŸ¤– ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼: {assistant_response}")
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¡¨ç¤º
            usage = response.usage
            print(f"ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: å…¥åŠ›={usage.prompt_tokens}, å‡ºåŠ›={usage.completion_tokens}, åˆè¨ˆ={usage.total_tokens}")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        
        print()
    
    print("=" * 60)
    print("ğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")

def compare_with_base_model():
    """ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
    
    if not load_environment():
        return
    
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    finetuned_model = "ft:gpt-4o-mini-2024-07-18:personal::CAJ6PxFB"
    base_model = "gpt-4o-mini"
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    test_message = [
        {"role": "user", "content": "æœ€è¿‘ã†ã¤æ°—åˆ†ã§ã€ä½•ã‚‚ã‚„ã‚‹æ°—ãŒèµ·ãã¾ã›ã‚“ã€‚ã©ã†ã—ãŸã‚‰ã„ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ"}
    ]
    
    print(f"\nğŸ”„ ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ")
    print("=" * 60)
    
    for model_name, model_id in [("ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«", base_model), ("ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", finetuned_model)]:
        print(f"\nğŸ¤– {model_name} ({model_id}):")
        print("-" * 40)
        
        try:
            response = client.chat.completions.create(
                model=model_id,
                messages=test_message,
                max_tokens=300,
                temperature=0.7
            )
            
            print(f"å¿œç­”: {response.choices[0].message.content}")
            print(f"ãƒˆãƒ¼ã‚¯ãƒ³: {response.usage.total_tokens}")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n=" * 60)
    print("ğŸ¯ æ¯”è¼ƒå®Œäº†ï¼ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ã‚¹ã‚¿ã‚¤ãƒ«ã®é•ã„ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def interactive_chat():
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒ£ãƒƒãƒˆ"""
    
    if not load_environment():
        return
    
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    model_id = "ft:gpt-4o-mini-2024-07-18:personal::CAJ6PxFB"
    
    print(f"\nğŸ’¬ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¨ã®å¯¾è©±é–‹å§‹")
    print(f"ãƒ¢ãƒ‡ãƒ«: {model_id}")
    print("çµ‚äº†ã™ã‚‹ã«ã¯ 'quit' ã¾ãŸã¯ 'exit' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„")
    print("=" * 60)
    
    messages = []
    
    while True:
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
            user_input = input("\nğŸ‘¤ ã‚ãªãŸ: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ å¯¾è©±ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
            
            if not user_input:
                continue
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ 
            messages.append({"role": "user", "content": user_input})
            
            # ãƒ¢ãƒ‡ãƒ«ã«é€ä¿¡
            response = client.chat.completions.create(
                model=model_id,
                messages=messages,
                max_tokens=400,
                temperature=0.7
            )
            
            # å¿œç­”ã‚’å–å¾—ãƒ»è¡¨ç¤º
            assistant_response = response.choices[0].message.content
            print(f"ğŸ¤– ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼: {assistant_response}")
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ 
            messages.append({"role": "assistant", "content": assistant_response})
            
            # é•·ããªã‚Šã™ããŸã‚‰å¤ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
            if len(messages) > 10:
                messages = messages[-8:]  # æœ€æ–°ã®8ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿æŒ
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å¯¾è©±ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break
        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸš€ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ« ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    while True:
        print("\né¸æŠã—ã¦ãã ã•ã„:")
        print("1. åŸºæœ¬ãƒ†ã‚¹ãƒˆï¼ˆè¤‡æ•°ã‚·ãƒŠãƒªã‚ªï¼‰")
        print("2. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒ")
        print("3. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆ")
        print("4. çµ‚äº†")
        
        choice = input("\nç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (1-4): ").strip()
        
        if choice == "1":
            test_finetuned_model()
        elif choice == "2":
            compare_with_base_model()
        elif choice == "3":
            interactive_chat()
        elif choice == "4":
            print("ğŸ‘‹ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚1-4ã®ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
